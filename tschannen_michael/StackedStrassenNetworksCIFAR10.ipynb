{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Linear Algebra in Stacked Strassen Networks\n",
    "\n",
    "This notebook provides a step-by-step implementation to reproduce the experiment in *Fast Linear Algebra in Stacked Strassen Networks* by Michael Tschannen, Aran Khanna, and Anima Anandkumar, submitted to the Machine Learning on the Phone and other Consumer Devices (MLPCD) NIPS 2018 workshop.\n",
    "\n",
    "#### Abstract\n",
    "\n",
    "Matrix multiplications can be cast as $2$-layer sum-product (SP) networks with ternary weight matrices, disentangling multiplications and additions. We leverage this observation for end-to-end learning of low cost (in terms of multiplications) approximations for linear operations in neural network layers. Specifically, we propose to replace matrix multiplication operations by SP networks, with widths corresponding to the budget of multiplications we want to allocate to each layer, and to learn them end-to-end. We showcase this approach by compressing the convolution layers of ResNet and evaluating it on CIFAR-10. We obtain a $98.96\\%$ reduction in the number of multiplications with an accuracy loss of only $0.82\\%$. \n",
    "\n",
    "\n",
    "#### Learning fast matrix multiplications via sum-product networks\n",
    "$\\renewcommand{\\vec}{\\mathrm{vec}}$Given square matrices $A, B \\in \\mathbb{R}^{n \\times n}$, the product $C = A B$ can be represented as a $2$-layer sum-product (SP) network (or ``Strassen network'')\n",
    "\n",
    "$$\n",
    "    \\label{eq:strnet}\n",
    "    \\vec(C) = W_C [ (W_B \\vec(B)) \\odot (W_A \\vec(A))] \\qquad \\qquad (1)\n",
    "$$\n",
    "\n",
    "where $W_A, W_B \\in \\mathbb{K}^{r \\times n^2}$ and $W_C \\in \\mathbb{K}^{n^2 \\times r}$, $\\mathbb{K}:= \\{-1,0,1\\}$, and $\\odot$ denotes the element-wise product.\n",
    "\n",
    "<img src=\"files/spnetwork.png\" alt=\"spnetwork\" style=\"width: 400px;\"/>\n",
    "\n",
    "1. $A, B\\in \\mathbb{R}^{2 \\times 2}$: Strassen's algorithm tells us ternary weights that satisfy (1) for $r=7$ (instead of $r = 8$).\n",
    "2. General case $A \\in \\mathbb{R}^{k \\times m}$, $B \\in \\mathbb{R}^{m \\times n}$: $C = A B$ can be written in the form (1) if $r \\geq nmk$.\n",
    "3. If $A \\in \\mathbb{R}^{k \\times m}$ is fixed and $B \\in \\mathbb{R}^{m \\times n}$ concentrates on low-dimensional subspace of $\\mathbb{R}^{k \\times m}$: Can find $W_A, W_B$ s.t. (1) holds approximately even when $r \\ll nmk$\n",
    "\n",
    "*Idea:* Leverage item 3 to learn low-cost (in terms of multiplications) approximate linear operations in neural network layers by associating $A$ with (pretrained) weights/filters and $B$ with corresponding activations/feature maps, and by learning $W_A$, $W_B$, $W_C$ end-to-end.\n",
    "\n",
    "In this notebook, we demonstrate this idea by compressing the 2D convolution layers of ResNet.\n",
    "\n",
    "#### Outline of the notebook:\n",
    "1. Implement the ternary quantization operator to learn ternary weights $W_B$ and $W_C$\n",
    "2. Implement the SP 2D convolution layer (i.e. a Strassen network for 2D convolutions)\n",
    "3. Implement residual blocks with SP layers and use these to construct a SP ResNet\n",
    "4. Define iterators and the training loop\n",
    "5. Train the network\n",
    "\n",
    "The code is base on Apache MXNet 0.12 and the gluon package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement the ternary quantization operator\n",
    "\n",
    "Following the tutorial from [1] to define custom gluon operators, we define an operator implementing the ternarization method proposed in [2]. Using the notation from [2], this method quantizes the entries of a given input tensor to values $\\{-\\alpha, 0, \\alpha\\}$ ($\\alpha$ corresponds to `scale` below) based on a threshold $\\Delta$ (corresponding to `thresh` below) on the full precision entries. $\\alpha$ and $\\Delta$ are determinined by approximately solving an optimization problem, see [2]. The operator will be used to quanzie $W_B$ and $W_C$ (the factor $\\alpha$ can be absorbed into $\\tilde a = W_A \\vec(A)$ after training to ensure that the entries of $W_B$ and $W_C$ are in $\\{-1,0,1\\}$). \n",
    "\n",
    "[1] https://github.com/apache/incubator-mxnet/blob/master/docs/tutorials/gluon/customop.md\n",
    "\n",
    "[2] F. Li, B. Zhang, B. Liu, Ternary Weight Networks, 2016, https://arxiv.org/abs/1605.04711v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages\n",
      "Requirement already satisfied: graphviz in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from mxnet)\n",
      "Requirement already satisfied: numpy in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from mxnet)\n",
      "Requirement already satisfied: requests in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from mxnet)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from requests->mxnet)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from requests->mxnet)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from requests->mxnet)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/nbcommon/anaconda3_420/lib/python3.5/site-packages (from requests->mxnet)\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "# define the quantization operator\n",
    "class TerQuant(mx.operator.CustomOp):\n",
    "    # define forward pass as described in [1]\n",
    "    def forward(self, is_train, req, in_data, out_data, aux):\n",
    "        full_data = in_data[0]\n",
    "\n",
    "        # compute $\\Delta$ as in [1], Eq. (6)\n",
    "        thresh = mx.nd.mean(mx.nd.abs(full_data), axis=()).asnumpy()[0] * 0.7\n",
    "\n",
    "        # ternarize weights\n",
    "        quant_data = mx.nd.greater(full_data, thresh*mx.nd.ones(full_data.shape, full_data.context))\\\n",
    "            - mx.nd.lesser(full_data, (-1.0)*thresh*mx.nd.ones(full_data.shape, full_data.context))\n",
    "\n",
    "        # compute $\\alpha$ as in [1], Eq. (5)\n",
    "        scale = mx.nd.sum(mx.nd.multiply(full_data, quant_data), axis=()).asnumpy()[0]\\\n",
    "            / mx.nd.sum(mx.nd.abs(quant_data), axis=()).asnumpy()[0]\n",
    "\n",
    "        # rescale ternary weights\n",
    "        quant_data = scale * quant_data\n",
    "        self.assign(out_data[0], req[0], quant_data)\n",
    "\n",
    "    # define backward pass: simply pass on gradient from previous operation (derivative of the identity function)\n",
    "    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):\n",
    "        self.assign(in_grad[0], req[0], out_grad[0])\n",
    "\n",
    "# wrap the operator and provide functions to get information about input, output etc.\n",
    "@mx.operator.register('ter_quant')\n",
    "class TerQuantProp(mx.operator.CustomOpProp):\n",
    "    def __init__(self):\n",
    "        super(TerQuantProp, self).__init__(True)\n",
    "\n",
    "    def list_arguments(self):\n",
    "        return ['data']\n",
    "\n",
    "    def list_outputs(self):\n",
    "        return ['output']\n",
    "\n",
    "    def infer_shape(self, in_shapes):\n",
    "        data_shape = in_shapes[0]\n",
    "        output_shape = data_shape\n",
    "        return (data_shape,), (output_shape,), ()\n",
    "\n",
    "    def create_operator(self, ctx, in_shapes, in_dtypes):\n",
    "        return TerQuant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement the SP 2DConvLayer\n",
    "$\\newcommand{\\cin}{c_\\mathrm{in}}\\newcommand{\\cout}{c_\\mathrm{out}}$We are now ready to implement the SP 2D convolution layer (as a gluon `HybridBlock` object). Specifically, we compress the computation of $\\cout \\times p \\times p$ output elements of the convolution from $\\cin \\times (p + 2\\lfloor k/2\\rfloor) \\times (p + 2\\lfloor k/2\\rfloor)$ input elements by applying (see figure below)\n",
    "\n",
    "1. a $p$-strided 2D convolution with a *ternary* filter of size $r \\times \\cin \\times (p + 2\\lfloor k/2\\rfloor) \\times (p + 2\\lfloor k/2\\rfloor)$ (corresponding to multiplication with $W_B$),\n",
    "2. a channel-wise multiplication with an $r \\times 1 \\times 1$ *full-precision* filter $\\tilde a = W_A \\vec(A)$ (corresponding to the filters of the original convolution),\n",
    "3. a $1/p$-strided transposed 2D convolution with a *ternary* filter of size $\\cout \\times r \\times p \\times p$ (corresponding to multiplication with $W_C$).\n",
    "\n",
    "<img src=\"files/sp2dconv.png\" alt=\"spnetwork\" style=\"width: 600px;\"/>\n",
    "\n",
    "As we will pretrain the convolutions described in items 1 and 3 above with full-precision weights, we include a variable `mode` that determines whether quantization is active or not. Furthermore, we include the original convolution to selectively replace the SP convolutions with ordinary ones (not used in this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon, autograd\n",
    "from mxnet.gluon.block import HybridBlock\n",
    "from mxnet.base import numeric_types\n",
    "from math import ceil\n",
    "\n",
    "class SumProd2DConv(mx.gluon.HybridBlock):\n",
    "    r\"\"\"\n",
    "    nbr_mul : int\n",
    "        Width of the sum-product network, corresponding to the number of multiplications r used to compute an\n",
    "        $p_x$ x $p_y$ x channels activation element\n",
    "    target_layer_shape:\n",
    "        Shape of the filter to be replaced by the sum-product network\n",
    "    target_layer_key:\n",
    "        Name of the target layer in the original ResNet (to enable loading from a pretrained network)\n",
    "    out_patch : int\n",
    "        size ($p_x$, $p_y$) of the output patch for spatial compression\n",
    "    kernel, stride, pad : specifics of the 2D convolution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nbr_mul, target_layer_shape, target_layer_key, out_patch=(1,1), kernel=(3,3), stride=(1,1), pad=(1,1), prefix=None, **kwargs):\n",
    "        # Use same prefix as parent layer for loading the shared paramters to be compressed\n",
    "        super(SumProd2DConv, self).__init__(prefix=prefix, **kwargs)\n",
    "\n",
    "        if isinstance(stride, numeric_types):\n",
    "            stride = (stride,)*len(kernel)\n",
    "        if isinstance(pad, numeric_types):\n",
    "            pad = (pad,)*len(kernel)\n",
    "\n",
    "        self._nbr_mul = nbr_mul\n",
    "        # corresponds to $p$ in the description above\n",
    "        self._out_patch = out_patch\n",
    "        self._kernel = kernel\n",
    "        self._stride = stride\n",
    "        self._pad = pad\n",
    "\n",
    "        # compute kernel shapes and stride for $W_B$\n",
    "        self._sp_data_weight_kernel = ((self._out_patch[0]-1)*self._stride[0]+self._kernel[0], (self._out_patch[1]-1)*self._stride[1]+self._kernel[1])\n",
    "        self._sp_data_weight_stride = (self._out_patch[0]*self._stride[0], self._out_patch[1]*self._stride[1])\n",
    "\n",
    "        # filters for the original convolution\n",
    "        self.filter_weights = self.params.get(target_layer_key, shape=target_layer_shape)\n",
    "\n",
    "        # Assuming the default NCHW layout, determine shapes of $W_B$ and $W_C$\n",
    "        filter_weights_shape = list(target_layer_shape)\n",
    "        sp_data_weights_shape = filter_weights_shape.copy()\n",
    "        sp_data_weights_shape[0] = nbr_mul\n",
    "        sp_data_weights_shape[2] = self._sp_data_weight_kernel[0]\n",
    "        sp_data_weights_shape[3] = self._sp_data_weight_kernel[1]\n",
    "        sp_out_weights_shape = filter_weights_shape.copy()\n",
    "        sp_out_weights_shape[0] = nbr_mul\n",
    "        sp_out_weights_shape[1] = filter_weights_shape[0]\n",
    "        sp_out_weights_shape[2] = self._out_patch[0]\n",
    "        sp_out_weights_shape[3] = self._out_patch[1]\n",
    "\n",
    "        ## SP network weights\n",
    "        # $\\tilde a = W_A \\vec(A)$\n",
    "        self.sp_in_weights = self.params.get('sp_in_weights', shape=(1,self._nbr_mul,1,1))\n",
    "        # $W_B$\n",
    "        self.sp_data_weights = self.params.get('sp_data_weights', shape=sp_data_weights_shape)\n",
    "        # $W_C$\n",
    "        self.sp_out_weights =  self.params.get('sp_out_weights', shape=sp_out_weights_shape)\n",
    "\n",
    "        # SP network batchnorm parameters\n",
    "        self.sp_batchnorm_gamma = self.params.get('sp_batchnorm_gamma', shape=(1,self._nbr_mul,1,1))\n",
    "        self.sp_batchnorm_beta = self.params.get('sp_batchnorm_beta', shape=(1,self._nbr_mul,1,1))\n",
    "        self.sp_batchnorm_running_mean = self.params.get('sp_batchnorm_running_mean', shape=(1,self._nbr_mul,1,1))\n",
    "        self.sp_batchnorm_running_var = self.params.get('sp_batchnorm_running_var', shape=(1,self._nbr_mul,1,1))\n",
    "\n",
    "        # mode: 1: original convolution; 2: SP network without ternary quantization; 3: SP network with ternary quantization\n",
    "        self.sp_mode = self.params.get('sp_mode', shape=(1,), dtype=np.uint8)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        with data.context:\n",
    "            mode = self.sp_mode.data().asnumpy()[0]\n",
    "            filter_weights = self.filter_weights.data()\n",
    "\n",
    "            if mode == 0:\n",
    "                # perform original convolution\n",
    "                conv_out = mx.nd.Convolution(data=data,\n",
    "                                  weight=filter_weights,\n",
    "                                  bias=None,\n",
    "                                  no_bias=True,\n",
    "                                  kernel=self._kernel,\n",
    "                                  stride=self._stride,\n",
    "                                  pad=self._pad,\n",
    "                                  num_filter=filter_weights.shape[0])\n",
    "\n",
    "                return conv_out\n",
    "            else:\n",
    "                sp_data_weights = self.sp_data_weights.data()\n",
    "                sp_out_weights = self.sp_out_weights.data()\n",
    "\n",
    "                # quantzie $W_B$ and $W_C$ if desired\n",
    "                if mode == 2:\n",
    "                    sp_data_weights = mx.nd.Custom(sp_data_weights, op_type='ter_quant')\n",
    "                    sp_out_weights = mx.nd.Custom(sp_out_weights, op_type='ter_quant')\n",
    "\n",
    "                pad_x = self._pad[0] + ceil((data.shape[2]%self._sp_data_weight_stride[0])/2)\n",
    "                pad_y = self._pad[1] + ceil((data.shape[3]%self._sp_data_weight_stride[1])/2)\n",
    "\n",
    "                # compute $W_B \\vec(B)$\n",
    "                sp_data_mul = mx.nd.Convolution(data=data,\n",
    "                                  weight=sp_data_weights,\n",
    "                                  bias=None,\n",
    "                                  no_bias=True,\n",
    "                                  kernel=self._sp_data_weight_kernel,\n",
    "                                  stride=self._sp_data_weight_stride,\n",
    "                                  pad=(pad_x, pad_y),\n",
    "                                  num_filter = self._nbr_mul)\n",
    "\n",
    "                # apply batchnorm to $W_B \\vec(B)$\n",
    "                sp_data_mul_norm = mx.nd.BatchNorm(data=sp_data_mul,\n",
    "                                              gamma=self.sp_batchnorm_gamma.data(),\n",
    "                                              beta=self.sp_batchnorm_beta.data(),\n",
    "                                              moving_mean=self.sp_batchnorm_running_mean.data(),\n",
    "                                              moving_var=self.sp_batchnorm_running_var.data(),\n",
    "                                              fix_gamma=True)\n",
    "\n",
    "                # apply non-negativity constraint to $\\tilde a = W_A \\vec(A)$\n",
    "                with mx.autograd.pause():\n",
    "                    self.sp_in_weights.set_data(mx.nd.clip(data=self.sp_in_weights.data(), a_min=0.0, a_max=100.0))\n",
    "                \n",
    "                # compute $(W_A \\vec(A)) \\odot (W_B \\vec(B))$\n",
    "                sp_mul = mx.nd.multiply(self.sp_in_weights.data(), sp_data_mul_norm)\n",
    "                \n",
    "                # compute $W_C[(W_A \\vec(A)) \\odot (W_B \\vec(B))]$\n",
    "                sp_out = mx.nd.Deconvolution(data = sp_mul,\n",
    "                                  weight = sp_out_weights,\n",
    "                                  bias = None,\n",
    "                                  no_bias = True,\n",
    "                                  kernel = self._out_patch,\n",
    "                                  stride = self._out_patch,\n",
    "                                  target_shape = (data.shape[2]//self._stride[0], data.shape[3]//self._stride[1]),\n",
    "                                  num_filter = filter_weights.shape[0])\n",
    "\n",
    "                return sp_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement the sum-product residual unit\n",
    "\n",
    "We continue by defining the residual unit as proposed in [3] using sum-product 2D convolutions. The code block below is adapted from [4] and looks lengthy, but there are only small modifications compared to [4]. Specifically, we replace ordinary 2D convolutions by sum-product 2D convolutions and add parameters for the sum-product convolutions.\n",
    "\n",
    "[3] K. He, X. Zhang, S. Ren, J. Sun, Deep Residual Learning for Image Recognition, 2016, http://arxiv.org/abs/1512.03385\n",
    "\n",
    "[4] https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/model_zoo/vision/resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "class BasicBlockV1SumProd(HybridBlock):\n",
    "    r\"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of output channels.\n",
    "    stride : int\n",
    "        Stride size.\n",
    "    nbr_mul : int\n",
    "        Width of the sum-product network, corresponding to the number of multiplications r used to compute an\n",
    "        $p_x$ x $p_y$ x channels activation element\n",
    "    out_patch : int\n",
    "        size ($p_x$, $p_y$) of the output patch for spatial compression\n",
    "    conv_idx : int\n",
    "        index of the convolution, used for parameter names\n",
    "    downsample : bool, default False\n",
    "        Whether to downsample the input.\n",
    "    in_channels : int, default 0\n",
    "        Number of input channels. Default is 0, to infer from the graph.\n",
    "    quant_down : bool\n",
    "        Whether to quantize ResNet 1x1 convolution projection layers\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, stride, nbr_mul, out_patch=(1,1), conv_idx=0, downsample=False, in_channels=0, quant_down=True, **kwargs):\n",
    "        super(BasicBlockV1SumProd, self).__init__(**kwargs)\n",
    "        self.body = nn.HybridSequential(prefix='')\n",
    "\n",
    "        prefix1 = 'conv%i_'%conv_idx\n",
    "        # shape of the original convolution\n",
    "        orig_shape1 = (channels, in_channels, 3, 3)\n",
    "        # kernel of the original convolution\n",
    "        kernel = (3,3)\n",
    "\n",
    "        self.body.add(SumProd2DConv(nbr_mul=nbr_mul,\n",
    "                                      target_layer_shape=orig_shape1,\n",
    "                                      target_layer_key='weight',\n",
    "                                      out_patch=out_patch,\n",
    "                                      kernel=kernel,\n",
    "                                      stride=stride,\n",
    "                                      prefix=prefix1))\n",
    "\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        self.body.add(nn.Activation('relu'))\n",
    "        \n",
    "        prefix2 = 'conv%i_'%(conv_idx+1)\n",
    "        orig_shape2 = (channels, channels, 3, 3)\n",
    "\n",
    "        self.body.add(SumProd2DConv(nbr_mul=nbr_mul,\n",
    "                                      target_layer_shape=orig_shape2,\n",
    "                                      target_layer_key='weight',\n",
    "                                      out_patch=out_patch,\n",
    "                                      kernel=kernel,\n",
    "                                      stride=1,\n",
    "                                      prefix=prefix2))\n",
    "\n",
    "        self.body.add(nn.BatchNorm())\n",
    "        \n",
    "        if downsample:\n",
    "            self.downsample = nn.HybridSequential(prefix='')\n",
    "\n",
    "            # Quantize projection layer if required\n",
    "            if quant_down:\n",
    "                prefix_ds = 'conv%i_'%(conv_idx+2)\n",
    "                orig_shape_ds = (channels, in_channels, 1, 1)\n",
    "\n",
    "                self.downsample.add(SumProd2DConv(nbr_mul=nbr_mul,\n",
    "                                              target_layer_shape=orig_shape_ds,\n",
    "                                              target_layer_key='weight',\n",
    "                                              out_patch=(1,1),\n",
    "                                              kernel=(1,1),\n",
    "                                              stride=stride,\n",
    "                                              pad=(0,0),\n",
    "                                              prefix=prefix_ds))\n",
    "            else:\n",
    "                self.downsample.add(nn.Conv2D(channels, kernel_size=1, strides=stride,\n",
    "                                              use_bias=False, in_channels=in_channels))\n",
    "\n",
    "            self.downsample.add(nn.BatchNorm())\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.body(x)\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        x = F.Activation(residual+x, act_type='relu')\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement the sum-product ResNet\n",
    "\n",
    "Again, we modify the code to construct ResNet (as a gluon `HybridBlock` object) for various dephts from [4], replacing ordinary 2D convolutions by sum-product 2D convolutions, and the fully connected output layer by a sum-product network if desired. As before, we add in some parameters for the sum-product networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.model_zoo.vision.resnet import _conv3x3\n",
    "\n",
    "class ResNetV1SumProd(HybridBlock):\n",
    "    r\"\"\"ResNet V1 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\"\n",
    "    <http://arxiv.org/abs/1512.03385>`_ paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : HybridBlock\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    channels : list of int\n",
    "        Numbers of channels in each block. Length should be one larger than layers list.\n",
    "    nbr_mul : int\n",
    "        Width of the sum-product network, corresponding to the number of multiplications r used to compute an\n",
    "        $p_x$ x $p_y$ x channels activation element\n",
    "    out_patch : int\n",
    "        size ($p_x$, $p_y$) of the output patch for spatial compression\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    thumbnail : bool, default False\n",
    "        Enable thumbnail.\n",
    "    quant_down : bool\n",
    "        Whether to quantize ResNet 1x1 convolution projection layers\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, channels, nbr_mul, out_patch, classes=1000, thumbnail=False, quant_down=True, prefix='resnetv10_', **kwargs):\n",
    "        super(ResNetV1SumProd, self).__init__(prefix, **kwargs)\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.features = nn.HybridSequential(prefix='')\n",
    "            # Thumbnail determines the characteristics of the first layer. If thumbnail==True, 3x3 convolutions are used\n",
    "            # and no pooling is performed (this setting is used for CIFAR). Otherwise, 7x7 filters with max-pooling are used.\n",
    "            if thumbnail:\n",
    "                # replace first layer with a sum-product layer if desired\n",
    "                if nbr_mul[0] > 0:\n",
    "                    orig_shape = (channels[0], 3, 3, 3)\n",
    "\n",
    "                    self.features.add(SumProd2DConv(nbr_mul = nbr_mul[0],\n",
    "                                                  target_layer_shape = orig_shape,\n",
    "                                                  target_layer_key = 'weight',\n",
    "                                                  kernel = (3, 3),\n",
    "                                                  stride = (1, 1),\n",
    "                                                  out_patch = out_patch[0],\n",
    "                                                  prefix = 'conv0_'))\n",
    "                else:\n",
    "                    self.features.add(_conv3x3(channels[0], 1, 3))\n",
    "\n",
    "            else:\n",
    "                # replace first layer with a sum-product layer if desired\n",
    "                if nbr_mul[0] > 0:\n",
    "                    orig_shape = (channels[0], 3, 7, 7)\n",
    "\n",
    "                    self.features.add(SumProd2DConv(nbr_mul = nbr_mul[0],\n",
    "                                                  target_layer_shape = orig_shape,\n",
    "                                                  target_layer_key = 'weight',\n",
    "                                                  kernel = (7, 7),\n",
    "                                                  stride = (2, 2),\n",
    "                                                  pad = (3,3),\n",
    "                                                  out_patch = out_patch[0],\n",
    "                                                  prefix = 'conv0_'))\n",
    "                else:\n",
    "                    self.features.add(nn.Conv2D(channels[0], 7, 2, 3, use_bias=False,\n",
    "                                                in_channels=3))\n",
    "                self.features.add(nn.BatchNorm())\n",
    "                self.features.add(nn.Activation('relu'))\n",
    "                self.features.add(nn.MaxPool2D(3, 2, 1))\n",
    "\n",
    "            for i, num_layer in enumerate(layers):\n",
    "                stride = 1 if i == 0 else 2\n",
    "                self.features.add(self._make_sumprod_layer(num_layer, channels[i+1], stride,\n",
    "                                                   nbr_mul[i+1], out_patch[i+1], i+1, in_channels=channels[i], quant_down=quant_down))\n",
    "\n",
    "            self.classifier = nn.HybridSequential(prefix='')\n",
    "            self.classifier.add(nn.GlobalAvgPool2D())\n",
    "            self.classifier.add(nn.Flatten())\n",
    "            self.classifier.add(nn.Dense(classes, in_units=channels[-1]))\n",
    "\n",
    "    # stack residual blocks as described in [2]\n",
    "    def _make_sumprod_layer(self, layers, channels, stride, nbr_mul, out_patch, stage_index, in_channels=0, quant_down=True):\n",
    "        layer = nn.HybridSequential(prefix='stage%d_'%stage_index)\n",
    "        with layer.name_scope():\n",
    "            layer.add(BasicBlockV1SumProd(channels, stride, nbr_mul, out_patch, 0, channels != in_channels, in_channels=in_channels, quant_down=quant_down, prefix=''))\n",
    "            nbr_conv = 2 if channels == in_channels else 3\n",
    "            for i in range(layers-1):\n",
    "                layer.add(BasicBlockV1SumProd(channels, 1, nbr_mul, out_patch, nbr_conv, False, in_channels=channels, quant_down=quant_down, prefix=''))\n",
    "                nbr_conv += 2\n",
    "        return layer\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training the network\n",
    "\n",
    "We are now ready to train and evaluate the SP-ResNet-20 on CIFAR-10 as described in the paper.\n",
    "\n",
    "We start by defining the SP-Resnet-20. The parameters below realize the configuration for $p=1$ and $r=c_\\mathrm{out}$ in Table 1 (first row, first column) in the paper, and can be modified for other configurations. Furthermore, the context can be modified below (use `ctx = [mx.cpu(0)]` if you don't have a GPU available, or extend to a list of devices for parallel training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CIFAR-10 has 10 classes\n",
    "classes = 10\n",
    "# structure of ResNet-20\n",
    "res_units = [3, 3, 3]\n",
    "res_channels = [16, 16, 32, 64]\n",
    "# choose the width of the sum-product convolution networks (i.e., $r$) to be equal to the number of output channels\n",
    "# don't compress the last layer (encoded by nbr_mul=0)\n",
    "nbr_mul = [16, 16, 32, 64, 0]\n",
    "# don't do spatial compression (out. patch=1x1)\n",
    "out_patch = [(1,1)]*4\n",
    "# quantize ResNet 1x1 convolution projection layers\n",
    "quant_down = True\n",
    "# use 3x3 kernels for the first convolution layer, don't do pooling after the first convolution layer\n",
    "thumbnail = True\n",
    "\n",
    "# construct ResNet HybridBlock object\n",
    "sp_resnet = ResNetV1SumProd(res_units, res_channels, nbr_mul, out_patch, classes, thumbnail, quant_down)\n",
    "\n",
    "# define context\n",
    "ctx = [mx.cpu(0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize the network parameters. As we first train all weights at full precision first, `sp_mode` is set to  1. `sp_in_weights` (corresponding to $\\tilde a = W_A \\mathrm{vec}(A)$) is initialized to 1s and Xavier initialization is used for `sp_data_weights` and `sp_out_weights` (corresponding to $W_B$ and $W_C$, respectively), and for the fully connected output layer. Furthermore, optimization is deactivated for the auxiliary batchnorm variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to filter and intialize paramters whose name contains a given substring\n",
    "def initialize_by_key(net, key, init, context, force_reinit=False):\n",
    "    for k, p in net.collect_params().items():\n",
    "        if key in k:\n",
    "            p.initialize(init=init, ctx=context, force_reinit=force_reinit)\n",
    "\n",
    "# initialize SP networks\n",
    "initialize_by_key(sp_resnet, 'sp_mode', mx.init.One(), ctx)\n",
    "initialize_by_key(sp_resnet, 'sp_in_weights', mx.init.One(), ctx)\n",
    "initialize_by_key(sp_resnet, 'sp_data_weights', mx.init.Xavier(magnitude=2), ctx)\n",
    "initialize_by_key(sp_resnet, 'sp_out_weights', mx.init.Xavier(magnitude=2), ctx)\n",
    "\n",
    "# intialize batchnorm parameters\n",
    "initialize_by_key(sp_resnet, 'gamma', mx.init.One(), ctx)\n",
    "initialize_by_key(sp_resnet, 'beta', mx.init.Zero(), ctx)\n",
    "initialize_by_key(sp_resnet, 'running_mean', mx.init.Zero(), ctx)\n",
    "initialize_by_key(sp_resnet, 'running_var', mx.init.Zero(), ctx)\n",
    "\n",
    "# initialize fully connected layer\n",
    "initialize_by_key(sp_resnet, 'dense0_weight', mx.init.Xavier(magnitude=2), ctx) #mx.init.Normal(1)\n",
    "initialize_by_key(sp_resnet, 'dense0_bias', mx.init.Zero(), ctx)\n",
    "\n",
    "# deactivate optimization for original convolutions as they are not used here\n",
    "for k, p in sp_resnet.collect_params().items():\n",
    "    if 'conv' in k and 'sp' not in k:\n",
    "        p.initialize(init=mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "        p.grad_req = 'null'\n",
    "\n",
    "# deactivate optimization for batchnorm auxiliary variables\n",
    "for k, p in sp_resnet.collect_params().items():\n",
    "    if 'running_mean' in k or 'running_var' in k or 'sp_mode' in k:\n",
    "        p.grad_req = 'null'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue by defining a testing routine and a training loop. This again looks lengthy but is standard and adapted from [5] with slight modifications.\n",
    "\n",
    "[5] https://github.com/apache/incubator-mxnet/blob/master/example/gluon/image_classification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def test(net, val_data, context):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    val_data.reset()\n",
    "    for batch in val_data:\n",
    "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=context, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=context, batch_axis=0)\n",
    "        outputs = []\n",
    "        for x in data:\n",
    "            outputs.append(net(x))\n",
    "        metric.update(label, outputs)\n",
    "    return metric.get()\n",
    "\n",
    "\n",
    "def train(net, lr, mom, wd, epochs, scheduler, context, train_data, val_data, log_interval):\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd',\n",
    "                            {'learning_rate': lr, 'wd': wd, 'momentum': mom, 'lr_scheduler': scheduler},\n",
    "                            kvstore = 'device')\n",
    "    metric = mx.metric.Accuracy()\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tic = time.time()\n",
    "        train_data.reset()\n",
    "        metric.reset()\n",
    "        btic = time.time()\n",
    "        for i, batch in enumerate(train_data):\n",
    "            data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "            label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "            outputs = []\n",
    "            Ls = []\n",
    "            with autograd.record():\n",
    "                for x, y in zip(data, label):\n",
    "                    z = net(x)\n",
    "                    L = loss(z, y)\n",
    "                    Ls.append(L)\n",
    "                    outputs.append(z)\n",
    "                for L in Ls:\n",
    "                    L.backward()\n",
    "            trainer.step(batch.data[0].shape[0])\n",
    "            metric.update(label, outputs)\n",
    "            if log_interval and not (i+1)%log_interval:\n",
    "                name, acc = metric.get()\n",
    "                print('Epoch[%d] Batch [%d]\\tSpeed: %f samples/sec\\t%s=%f'%(\n",
    "                               epoch, i, batch_size/(time.time()-btic), name, acc))\n",
    "            btic = ti